---
title: 'The Sparse Coupling Conjecture: New Results'
date: 2022-07-18
permalink: /posts/2022/06/SCC/
layout: post
usemathjax: true
published: false
tags:
  - projects and papers
  - reading guides
  - Bayesian mechanics
---

In a recent paper of mine, [arXiv...](...), I give a set of proofs that resolve (to the best extent possible, anyway) an open question in the study of complex systems and random dynamics. Here I'll discuss the conjecture (including relevant background), and my results, at a high-level.

Regular readers of this blog will most likely be familiar with the name [Karl Friston](https://www.fil.ion.ucl.ac.uk/~karl/) and will find this superfluous. Folks from a broader audience might want to read it. In a [2021 paper](https://www.mdpi.com/1099-4300/23/9/1220/htm)—first appearing a year and a week ago, in fact, although the problem was being discussed for some time prior to this—a colleague and close collaborator of mine, Karl Friston, introduced the _sparse coupling conjecture_, a statement motivated by the structure of a particular class of random dynamical system relevant for complex systems theory (and statistical physics more broadly, in fact). Take two coupled random dynamical systems, interacting in such a way that they are separable, i.e., are statistically distinguishable. That is, either (in fact, both) system's statistics are conditionally independent of the other respective system, making them measurable and hence statistically distinct. This sort of structure is called a Markov blanket. The SCC is a conjecture that any sufficiently high-dimensional system with non-linearities and which exhibits certain features of complexity possesses a Markov blanket. There is a deeper statement that a Markov blanket is the source (or, the reflection) of such complexity, and this is one way of thinking about Bayesian mechanics.[^1] However, purely mathematically, it is a statement that a certain class of systems with some properties that make them useful models of physics also come with the property of having a Markov blanket. 

What is a Markov blanket? [thing about fast mixing]

The sparse coupling conjecture is, in particular, a statement that all sufficiently high-dimensional and non-linear [random dynamical] systems have a Markov blanket. Some reasons why we might expect this are outlined in the introduction: high-dimensional and non-linear systems are usually the sorts of complex systems that can engage in complex behaviours to remain cohesive. They are usually better at control, computation, and self-organisation; see the high-dimensionality of the brain or deep learning architectures, or the non-linearities in Turing pattern PDEs. Simply thinking mathematically, in larger state spaces there will be fewer states coupled at all, so as dimension increases the coupling structure will become sparser: not every state will couple to every other state. 

[weaken it and you get better results and you make more physical sense. this is probably not a coincidence]

[We turn a topological problem of classifying all DSs of a certain sort into a probabilistic one of how frequent certain DSs are back into a state space problem of the geometry of the space of such DSs. How many indices are small? Where are they? This subtelty is somewhat hidden but it's the reason why the whole business works.]

Some intuitions for this result. In high-dimensions there are many more orthogonal directions. And, there are $$e^n$$ almost-orthogonal unit vectors in $$n$$-dimensions (if one were to prove this they would use exactly the Hoeffding inequality). Also imagine that dimension reduction is a thing which leads to our submanifold question. Since maintaining an MB is exactly enforcing one such system-like attractor: a submanifold for the system: this is something we could take an interest in. We also have the intuition that higher-dimensional systems have more room to be sparse since they have more directions in which to flow, and additionally, more room to generate such submanifolds and still remain 'systemic'\textemdash that is, these submanifolds can be larger and exhibit interesting dynamics in higher-dimensional systems.

The SCC is a mathematical statement, just about high-dimensional and non-linear systems. We need to assume sparsity for it to make physical sense, and also to get decent results; but this is still a set of full measure and also allows us to get good results, whereas counterexamples exist on set of measure zero.

Adiabatically we are thinking of the fact that things do not couple to things that change too fast. Certain variables change fast, implying a decoupling in slow variables. This also clarifies our hypothesis in Theorem \ref{main-result} that the mean ought to be zero. In high-dimensional systems, not every internal degree of freedom will couple to every external degree of freedom, making the measure on products of $Q$ and $H$ zero in expectation. Using this result we were able to show that the deviation from this average under the Chernoff bound is, when suitably normalised, limitingly zero. 


Certain random dynamical systems have the structure of a Markov blanket. This is an interesting feature relevant for physical systems for x y and z reasons.

Markov blankets can be found almost everywhere, in the literal measure-theoretic sense of almost everywhere and consequently the colloquial sense of existing for essentially every system (certainly every interesting, non-trivial, physically-realistic system). 


So, we have a problem: MBs are too restrictive to make physical sense. It just so happens that they are difficult to construct. Can we prove that blankets exist weakly and that they ought to exist weakly? Yes (small but non-zero inner products) and yes (adiabatic stuff, material exchange stuff)

So there are heuristic but mathematically solid arguments that this blanket, and in particular, the weakening of the blanket structure, can be expected to be ubiquitous in high-dimensional systems. These arguments partially formalise the intuition that there is simply too much 'room' in the degrees of freedom of a high-dimensional system to \emph{not} be sparsely coupled, and hence, will (almost) certainly have a weak blanket. That motivates the following weakening of the sparse coupling conjecture:

...

Simplicity, however, is most always an adiabatic approximation to microscopic complexity.  

In some sense we have given a dual result: weak Markov blankets are exceedingly common,  indeed,  almost tautological. More faithful blankets where each such index vanishes are much more difficult to find in general but are exceedingly common, indeed almost definitional, of high-dimensional systems.

How do stone-like things self-assemble into a large stone-like MB? A problem of timescales.

In some sense, the following result formalises the intuition that high-dimensional systems are better at control and computation. Further, it sheds light on the ubiquity of Markov blankets in systems that do not mix. Recall the statement of the sparse coupling conjecture in the previous section. 

A simple counting argument is a nice intuition: 

\begin{prop}
For ternary $Q$ and $H$ and arbitrary $\eta^i\mu^j$, as dimension increases, 
\[
\abs{\frac{\Ind(J_{\eta^i\mu^j})}{\Ind_{\emph{max}}(J_{\eta^i\mu^j})}} \to 0
\]
with probability one under a uniform measure on entries in $Q$ and $H$.
\end{prop}
\begin{proof}
Let $\bm F_3$ be the field $\{-1, 0, 1\}$ and suppose entries in $Q$ and $H$ are valued in $\bm F_3$ (i.e., $Q$ and $H$ are ternary matrices), with those values chosen uniformly. Then we have the prefactor given by Lemma \ref{ll-implies-NSCC} in \eqref{norm-b-index-ll-1} and seek to prove that $\abs{\Ind(J_{\eta^i\mu^j})}\ll n-1$ for arbitrary pairs of $Q$ and $H$ elements with probability one as $n$ increases. The inner product $\Ind(J_{\eta^i\mu^j})$ is a sum over $n-1$ pairs of items in $\bm F_3$, since these are the possible values for entries in $Q_{\eta^i}$ and $H_{\mu^j}$. This completely determines the value of $\Ind(J_{\eta^i\mu^j})$ as a function of the coefficients of $Q_{\eta^i}$ and $H_{\mu^j}$ regarded as vectors. Assuming the items in any such pair are ordered, we can enumerate the set of possible $Q_{\eta^i}$ and $H_{\mu^j}$ configurations by enumerating every way to choose $n-1$ combinations of pairs of $\bm F_3$ elements. That is to say, since $Q_{\eta^i}$ and $H_{\mu^j}$ are $n-1$ dimensional ternary vectors, and there are $3^{2(n-1)}$ ways of forming pairs from three elements $n-1$ times, given that order matters, there are $3^{2(n-1)}$ unique ways to have configurations of $(Q_{\eta^i}, H_{\mu^j})$. We now have the following: for the blanket index of almost every ternary $J_{\eta^i\mu^j}$ to be small as $n$ increases, the probability that $\abs{\Ind(J_{\eta^i\mu^j})} \ll n-1$ needs to be near $3^{2(n-1)}$. In this way, every configuration of $J_{\eta^i\mu^j}$ is likely to have small blanket index as $n$ gets large. Since there are two sets of ways of making maximal combinations of entries (we have $n-1$ pairs valued in $\{-1, 1\}$ or $\{1, -1\}$ and $n-1$ pairs valued in $\{-1, -1\}$ or $\{1, 1\}$, both of which yield $\abs{\Ind(J_{\eta^i\mu^j})}\ll n-1$), the number of maximal combinations of entries is $2(4^{n-1})$. This means that there are $9^{n-1} - 2(2^{2(n-1)})$ ways of producing a non-maximal blanket index where $\abs{\Ind(J_{\eta^i\mu^j})}\ll n-1$ by construction. The probability of not choosing one of these methods under a uniform distribution is 
\[
\frac{9^{n-1} - 2(4^{n-1})}{9^{n-1}},
\]
which clearly goes to one quickly with increasing $n$.
\end{proof}
 
[^1]: For more, see the following page: [darsakthi.github.io/research](https://darsakthi.github.io/research/).
